---
title: "Workshop_ML"
author: "Abhay Singh"
date: "23/07/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# R for Machine Learning

## Random Sampling

- Data splitting: 70:30 (70: Training; 30: Testing)

```{r}
library(quantmod)

bhp=getSymbols("BHP.AX",from="2018-01-01",to="2020-07-31",auto.assign = FALSE)
head(bhp)
d_bhp=bhp$BHP.AX.Close
head(d_bhp)
plot(d_bhp)

d_bhp=data.frame(Date=as.Date(index(d_bhp)),Price=coredata(d_bhp))
head(d_bhp)
```

- Base R for data splitting

```{r}
set.seed(999)#sets the random number generator seed

idx1=sample(1:nrow(d_bhp),round(nrow(d_bhp)*0.7))
#idx1
train1=d_bhp[idx1,]
test1=d_bhp[-idx1,]
nrow(train1)
nrow(test1)
```

### Visualisation

```{r}
library(ggplot2)
p1=ggplot(train1,aes(x=BHP.AX.Close))+geom_density(trim=TRUE,aes(color="Training"),size=1)
p1=p1+geom_density(data=test1,aes(x=BHP.AX.Close,color="Testing"),size=1,linetype=2)
```

### The caret package

```{r}
set.seed(999)

library(caret)
idx2=createDataPartition(d_bhp$BHP.AX.Close,p=0.7,list=FALSE)
train2=d_bhp[idx2,]
test2=d_bhp[-idx2,]

p2=ggplot(train2,aes(x=BHP.AX.Close))+geom_density(trim=TRUE,aes(color="Training"),size=1)
p2=p2+geom_density(data=test2,aes(x=BHP.AX.Close,color="Testing"),size=1,linetype=2)

```

### Using the rsample package

```{r}
set.seed(999)
library(rsample)
idx3=initial_split(d_bhp,prop=0.7)
train3=training(idx3)
test3=testing(idx3)


p3=ggplot(train3,aes(x=BHP.AX.Close))+geom_density(trim=TRUE,aes(color="Training"),size=1)
p3=p3+geom_density(data=test3,aes(x=BHP.AX.Close,color="Testing"),size=1,linetype=2)

```

- Arrange them all together

```{r,fig.width=10}
library(gridExtra)
grid.arrange(p1,p2,p3,nrow=1)
```


### Stratified Sampling

- Use the GermanCredit data

```{r}
set.seed(999)
data("GermanCredit")
head(GermanCredit)

idx4=initial_split(GermanCredit,prop=0.7,strata="Class")
train4=training(idx4)
test4=testing(idx4)

prop.table(table(train4$Class))
prop.table(table(test4$Class))
```


## Resampling

### K-fold Cross Validation

- rsample package

```{r}
set.seed(999)
cv1=vfold_cv(d_bhp[2],v=10)
cv1
```


- caret package

```{r}
cv2=createFolds(d_bhp$BHP.AX.Close,k=10)
cv2$Fold01
```


### Time series cross validate


```{r}
d_bhp2=xts(d_bhp$BHP.AX.Close,order.by = d_bhp$Date)
cv_ts=createTimeSlices(d_bhp2,initialWindow = 500,horizon=100,fixedWindow = TRUE)
cv_ts$train$Training500
```



### Bootstrapping

```{r}
boot1=bootstraps(d_bhp2[2],times=10)
boot1
```



# Logistic Regression & KNN

- Create the indicators


```{r}
library(quantmod)
library(TTR)
library(xts)
d_bhp=bhp$BHP.AX.Close
plot(d_bhp)

colnames(d_bhp)="Price"

#SMA

sma5=lag(SMA(d_bhp,n=5))
#EMA

ema5=lag(EMA(d_bhp,n=5))
#MACD
macd1=lag(MACD(d_bhp))

#RSI
rsi1=lag(RSI(d_bhp,5))

#returns

ret1=lag(dailyReturn(d_bhp,type="log"))


dir=ifelse(d_bhp$Price>=lag(d_bhp$Price,5),1,0)

```


- Combine the indicators

```{r}
d_ex1=cbind(dir,ret1,sma5,ema5,macd1,rsi1)
head(d_ex1)

colnames(d_ex1)=c("Direction","Ret","SMA","EMA","MACD","Signal","RSI")
head(d_ex1)
```



- Visualise the data

```{r}
chartSeries(d_bhp,theme="white",name="BHP Prices & Indicators")
addTA(d_ex1[,1],col=1,legend="Direction")
addTA(d_ex1[,-1],on=NA,col=rainbow(6),legend=as.character(colnames(d_ex1[,-1])))
```



- Use ggplot2

```{r}
library(tidyr)
library(ggplot2)
d_plot=merge(d_bhp,d_ex1)
head(d_plot)

d_plot=na.omit(d_plot)

#convert it to long format for plotting

d_plot2=data.frame(Date=index(d_plot),coredata(d_plot))
head(d_plot2)
d_plot_long=pivot_longer(d_plot2,-c(Date,Direction),values_to="value",names_to="Indicator")

d_plot_long$Direction=as.factor(d_plot_long$Direction)


p2_ex=ggplot(d_plot_long,aes(Date,value,color=Indicator))+geom_path(stat="identity")+
  facet_grid(Indicator~.,scale="free")+theme_minimal()
p2_ex


p3_ex=ggplot(d_plot_long,aes(value,Indicator,fill=Direction))+geom_boxplot()
p3_ex+theme_minimal()
```


## Using Logistic Regression

- 70:30 split
- Time series sampling

```{r}
head(d_ex1)
d_ex1=na.omit(d_ex1)
d_ex1=as.data.frame(d_ex1)
d_ex1$Direction=as.factor(d_ex1$Direction)
#str(d_ex1)

#data splitting

idx1=c(1:round(nrow(d_ex1)*0.7))

d_train1=d_ex1[idx1,]
d_test1=d_ex1[-idx1,]
#head(d_train1)


```



### Training setup

- Time series cross validate
- 250 days in a window and 30 days for horizon
- Data preprocessing to normalise that

- Formula

$$ Direction\tilde\, \beta_0 +\beta_1*SMA + \beta_2*SMA + \beta_3*RSI...$$ 





```{r}
library(caret)
set.seed(999)
cntrl1=trainControl(method="timeslice",initialWindow = 250,horizon = 30,fixedWindow = TRUE)

prep1=c("center","scale")

logit_ex1=train(Direction~.,data=d_train1,method="glm",family="binomial",trControl=cntrl1,preProces=prep1)
```


```{r}
logit_ex1
summary(logit_ex1$finalModel)
```

```{r}
library(vip)
vip(logit_ex1)
```



### Predictive Accuracy

```{r}
pred1=predict(logit_ex1,newdata = d_test1)
confusionMatrix(data=pred1,reference=d_test1$Direction)
```




### Knn application

```{r}
set.seed(999)
grid1=expand.grid(k=seq(1,20,by=1))

knn_ex1=train(Direction~.,data=d_train1,method="knn",tuneGrid=grid1,trControl=cntrl1,preProces=prep1)
```




```{r}
knn_ex1$bestTune
plot(knn_ex1)
```




- Predictive Accuracy

```{r}
pred2=predict(knn_ex1,newdata = d_test1)
confusionMatrix(data=pred2,reference=d_test1$Direction)
```


```{r}
resamp1=resamples(list(logit=logit_ex1,knn=knn_ex1))
bwplot(resamp1,metric="Accuracy")
```





